# teamNemo.py
# ---------
# Licensing Information: Please do not distribute or publish solutions to this
# project. You are free to use and extend these projects for educational
# purposes. The Pacman AI projects were developed at UC Berkeley, primarily by
# John DeNero (denero@cs.berkeley.edu) and Dan Klein (klein@cs.berkeley.edu).
# For more info, see http://inst.eecs.berkeley.edu/~cs188/sp09/pacman.html

from captureAgents import CaptureAgent
import random
import time
import util
import itertools
from game import Directions
import game
import distanceCalculator
import math
from util import nearestPoint
import copy


#################
# Team creation #
#################

def createTeam(firstIndex, secondIndex, isRed,
               first='Agent007', second='Agent007'):
    """
    This function should return a list of two agents that will form the
    team, initialized using firstIndex and secondIndex as their agent
    index numbers.  isRed is True if the red team is being created, and
    will be False if the blue team is being created.

    As a potentially helpful development aid, this function can take
    additional string-valued keyword arguments ("first" and "second" are
    such arguments in the case of this function), which will come from
    the --redOpts and --blueOpts command-line arguments to capture.py.
    For the nightly contest, however, your team will be created without
    any extra arguments, so you should make sure that the default
    behavior is what you want for the nightly contest.
    """

    # The following line is an example only; feel free to change it.
    firstAgent = eval(first)(firstIndex)
    secondAgent = eval(second)(secondIndex)
    team = [firstAgent, secondAgent]

    firstAgent.registerTeam(team)
    secondAgent.registerTeam(team)

    firstAgent.registerAlly(secondAgent, secondIndex)
    secondAgent.registerAlly(firstAgent, firstIndex)

    return team


##########
# Agents #
##########

class Agent007(CaptureAgent):
    """
    An agent that would use following techniques:
    1) combination of expectimax, greedy tracking, and feature-based decisions
    2) particle filters for tracking the enemy agents
    3) different strategy for abstract states

    The strategies to implement are the following:
    1) At the start, wait at the edge and devour enemy for the initial
       Pwnage. I mean, advantage. Whenever enemy ghost approaches and
       the agent is ghost too, then wait until the enemy transforms.
    2) Never run into unscared enemy ghost. Ever.
    3) If nearby enemy pacman found (a pacman will still pursue if close, but
       a ghost can see further), track it down in a greedy sense (in terms of
       distance). One enemy ghost is tracked down by only one of our agents.
    4) If out in the field and no nearby ghost, create an MST of food using
       Kruskal's algorithm and explore from the branch to the shortest leaf.
       It used to eat from the closest food in a greedy fashion (longest streak
       of food), but it turns out that it would leave bunch of food here and
       there instead of eating from that side of the screen. One agents covers
       only an upper or lower half of the screen unless the food there ran out.
    5) If out in the field and unscared enemy ghosts approach, use expectimax
       to escape from the tight corner while looking for food and capsule.

    Also, the particle filter and expectimax in this agent are peculiar.

    PF - 1) On each turn, only the last-moved agent's particle is updated.
         2) The data is indirectly triangulated. That is, on each turn,
            an agent updates its ally's particles too.
         3) The uniform initialization is randomized because of the big map.

    EXPMAX - Minimization is determined by distance from the enemies,
             not simulated states. This also decreases the amount of
             calculation substantially, but it is slightly buggy.

    Finally, the agents think they are either James Bond or
    Johnny English(aka. Mr. Bean), and will speak lines.
    """
    def __init__(self, index, timeForComputing=.1):
        CaptureAgent.__init__(self, index, timeForComputing)
        self.allyAgent = None

    def registerInitialState(self, gameState):
        """
        This method handles the initial setup of the
        agent to populate useful fields (such as what team
        we're on).

        A distanceCalculator instance caches the maze distances
        between each pair of positions, so your agents can use:
        self.distancer.getDistance(p1, p2)

        IMPORTANT: This method may run for at most 15 seconds.
        """

        # Original parent function
        # CaptureAgent.registerInitialState(self, gameState)

        '''
        Your initialization code goes here, if you need any.
        '''
        # #### Original parent function starts #####
        self.red = gameState.isOnRedTeam(self.index)
        self.distancer = distanceCalculator.Distancer(gameState.data.layout)

        # comment for manhattanDist, uncomment for mazeDist
        self.distancer.getMazeDistances()

        import __main__
        if '_display' in dir(__main__):
            self.display = __main__._display
        # #### Original parent function ends #####

        # My initialization

        self.legalPositions = gameState.getWalls().asList(False)
        self.legalPosSet = set(self.legalPositions)

        self.numAgents = gameState.getNumAgents()
        self.teamIndices = self.getTeam(gameState)
        self.enemyIndices = self.getOpponents(gameState)
        self.numAllFood = len(self.foodList(gameState))
        
        print "Agent " + str(self.index) + " initializing..."
        print "- and mister...?"
        if self.index == self.teamIndices[0]:
            print "- Bond. James Bond."
        else:
            print "- English. Johnny English."

        if self.index == self.teamIndices[0]:
            self.allyIndex = self.teamIndices[1]
        else:
            self.allyIndex = self.teamIndices[0]

        self.startPositions = [gameState.getInitialAgentPosition(i)
                               for i in range(self.numAgents)]

        self.arenaWidth = gameState.getWalls().width
        self.arenaHeight = gameState.getWalls().height

        self.numParticles = 400
        self.initializeAllParticles()

        self.depth = 10
        self.foodDepth = 12
        self.minimaxDist = 5
        self.discount = 0.9
        self.probLogicalEnemy = 0.5
        self.hound = False
        self.target = -1
        if self.startPositions[self.index][1] > self.startPositions[self.allyIndex][1]:
            self.upper = True
        else:
            self.upper = False

        self.defFood = None

        pos = self.currentPosition(gameState)
        #mst = self.findFoodMST(gameState)
        #self.goalFood = self.findShortestBranchLeaf(mst, pos)
        fdlst = []
        x = 0
        if self.upper:
            while not fdlst:
                fdlst = list(filter(lambda z: z[1] > self.arenaHeight - x,
                    self.foodList(gameState)))
                x += 1
        #    fdlst = self.upperFoodList(gameState)
        else:
            while not fdlst:
                fdlst = list(filter(lambda z: z[1] < x,
                    self.foodList(gameState)))
                x += 1
        #    fdlst = self.lowerFoodList(gameState)
        fdlstDist = list(map(lambda p: self.getMazeDistance(pos, p), fdlst))

        self.goalFood = fdlst[fdlstDist.index(min(fdlstDist))]
        self.foodBranch = util.Queue()

    def registerAlly(self, allyAgent, allyIndex):
        self.allyAgent = allyAgent
        self.allyIndex = allyIndex

    def currentPosition(self, gameState):
        return gameState.getAgentState(self.index).getPosition()

    def currentAllyPosition(self, gameState):
        return gameState.getAgentState(self.allyIndex).getPosition()

    def approxEnemyPosition(self, index):
        return self.getBeliefDistribution()[index].argMax()

    def isScared(self, gameState, index):
        return gameState.getAgentState(index).scaredTimer > 0

    def isPacman(self, gameState, index):
        return gameState.getAgentState(index).isPacman

    def isEnemyEdible(self, gameState, enemyIndex):
        enemyIsPacman = gameState.getAgentState(enemyIndex).isPacman
        ediblePacman = enemyIsPacman# and not self.isScared(gameState, self.index)
        edibleGhost = gameState.getAgentState(enemyIndex).scaredTimer > 0
        return ediblePacman or edibleGhost

    def foodList(self, gameState):
        return self.getFood(gameState).asList(True)

    def upperFoodList(self, gameState):
        """
        food for the upper half of the screen
        """
        return list(filter(lambda x: x[1] >= self.arenaHeight / 2 - 1,
                           self.foodList(gameState)))

    def lowerFoodList(self, gameState):
        """
        food for the lower half of the screen
        """
        return list(filter(lambda x: x[1] < self.arenaHeight / 2 + 1,
                           self.foodList(gameState)))

    def adjustedFoodList(self, gameState):
        """
        all food if it's running out, else only half
        """
        foodList = []
        if self.upper:
            foodList = self.upperFoodList(gameState)
        else:
            foodList = self.lowerFoodList(gameState)
        if len(foodList) <= 4:
            foodList = self.foodList(gameState)
        return foodList

    def findFoodMST(self, gameState):
        """
        find the MST spanning all food and current position
        """
        foodList = self.adjustedFoodList(gameState)
        pos = self.currentPosition(gameState)
        foodList.append(pos)
        foodEdgeDict = util.Counter()
        # get the length of all edges
        for srcfood in foodList:
            for dstfood in foodList:
                if srcfood != dstfood:
                    dist = self.getMazeDistance(srcfood, dstfood)
                    foodEdgeDict[(srcfood, dstfood)] = dist
        # Kruskal's algorithm
        edgeList = foodEdgeDict.sortedKeys()[::-1]
        mstDict = {}
        visitedV = set()
        foodSet = set(foodList)
        for food in foodList:
            mstDict[food] = set()
        for edge in edgeList:
            v1, v2 = edge
            if not self.findVertex(mstDict, v1, v2):
                mstDict[v1].add(v2)
                mstDict[v2].add(v1)
            if foodSet == self.traverseTree(mstDict):
                break
        return mstDict

    def findShortestBranchLength(self, tree, s):
        """
        find the length of the shortest branch
        """
        q = util.PriorityQueue()
        q.push((s, 0), 0)
        visited = set()
        while not q.isEmpty():
            s, d = q.pop()
            visited.add(s)
            if len(tree[s] - visited) == 0:
                return d
            for v in tree[s]:
                if v not in visited:
                    newd = d + self.getMazeDistance(s, v)
                    q.push((v, newd), newd)

    def findShortestBranchLeaf(self, tree, s):
        """
        find the leaf of the shortest branch
        """
        q = util.PriorityQueue()
        q.push((s, 0), 0)
        visited = set()
        while not q.isEmpty():
            s, d = q.pop()
            visited.add(s)
            if len(tree[s] - visited) == 0:
                return s
            for v in tree[s]:
                if v not in visited:
                    newd = d + self.getMazeDistance(s, v)
                    q.push((v, newd), newd)

    def findShortestBranch(self, tree, s):
        """
        find the shortest branch and push into queue
        """
        q = util.PriorityQueue()
        retQ = util.Queue()
        q.push((s, 0, retQ), 0)
        visited = set()
        while not q.isEmpty():
            s, d, retQ = q.pop()
            visited.add(s)
            retQ.push(s)
            if len(tree[s] - visited) == 0:
                return retQ
            for v in tree[s]:
                if v not in visited:
                    newd = d + self.getMazeDistance(s, v)
                    q.push((v, newd, copy.copy(retQ)), newd)

    def findVertex(self, tree, s, v):
        q = util.Queue()
        q.push(s)
        visited = set()
        while not q.isEmpty():
            s = q.pop()
            if s == v:
                return True
            visited.add(s)
            for vert in tree[s]:
                if vert not in visited:
                    q.push(vert)
        return False

    def traverseTree(self, tree):
        q = util.Queue()
        q.push(tree.keys()[0])
        visited = set()
        while not q.isEmpty():
            s = q.pop()
            visited.add(s)
            for vert in tree[s]:
                if vert not in visited:
                    q.push(vert)
        return visited

    def getDefendingFood(self, gameState):
        self.defFood = set(self.getFoodYouAreDefending(gameState).asList(True))

    def closestDistanceAmongList(self, pos, posList):
        if pos in posList:
            return 0
        else:
            return min(map(lambda p: self.getMazeDistance(pos, p), posList))

    def foodSearch(self, gameState, action):
        """
        return the max number of food you can get within self.foodDepth
        """
        depth = 0
        skipped = 0
        maxDepth = self.foodDepth

        succ = self.getSuccessor(gameState, action)
        oldPos = self.currentPosition(gameState)
        newPos = self.currentPosition(succ)
        foodList = self.adjustedFoodList(gameState)

        visited = {(oldPos, hash(tuple(foodList)), skipped)}
        toVisit = util.Queue()
        foodAte = 0
        maxFoodAte = 0

        if newPos in foodList:
            foodList.remove(newPos)
            foodAte += 1

        toVisit.push((newPos, foodAte, foodList, depth, skipped))

        while not toVisit.isEmpty() and depth <= maxDepth:
            pos, foodAte, foodList, depth, skipped = toVisit.pop()
            succPos = self.successorPos(pos)

            if (pos, hash(tuple(foodList)), skipped) in visited:
                continue
            elif pos not in foodList:
                skipped += 1
                if skipped > 1:
                    continue
            else:
                foodAte += 1
                foodList.remove(pos)

            visited.add((pos, hash(tuple(foodList)), skipped))

            if foodAte > maxFoodAte:
                maxFoodAte = foodAte

            if len(foodList) <= 1:
                foodList = self.foodList(succ)

            depth += 1

            for p in succPos:
                toVisit.push((p, foodAte, foodList, depth, skipped))

        return maxFoodAte

    def closestPacman(self, gameState):
        """
        index and coordinate of the closest enemy
        """
        allDistrib = self.getBeliefDistribution()
        allPos = []
        for i in range(self.numAgents):
            if i in self.enemyIndices:
                allPos.append(allDistrib[i].argMax())
            else:
                allPos.append((0,0))

        newPos = self.currentPosition(gameState)
        enemyPacmanPos = []

        for i in range(self.numAgents):
            if i in self.enemyIndices:
                if gameState.getAgentState(i).isPacman:
                    enemyPacmanPos.append(allDistrib[i].argMax())
        enemyPacmanDist = \
            list(map(lambda x: self.getMazeDistance(newPos, x), enemyPacmanPos))
        if not enemyPacmanDist:
            return -1
        minDist = min(enemyPacmanDist)
        minPos = enemyPacmanPos[enemyPacmanDist.index(minDist)]
        i = allPos.index(minPos)
        return i

    def closestGhost(self, gameState):
        """
        index of the closest enemy
        """
        allDistrib = self.getBeliefDistribution()
        allPos = []

        e1 = self.enemyIndices[0]
        e2 = self.enemyIndices[1]

        if self.isPacman(gameState, e1) and self.isPacman(gameState, e2):
            return -1
        elif self.isPacman(gameState, e1) and not self.isPacman(gameState, e2):
            if self.isScared(gameState, e2):
                return -1
            else:
                return e2
        elif not self.isPacman(gameState, e1) and self.isPacman(gameState, e2):
            if self.isScared(gameState, e1):
                return -1
            else:
                return e1
        else:
            if self.isScared(gameState, e1) and self.isScared(gameState, e2):
                return -1
            elif self.isScared(gameState, e1):
                return e2
            elif self.isScared(gameState, e2):
                return e1
            else:
                e1pos = self.approxEnemyPosition(e1)
                e2pos = self.approxEnemyPosition(e2)
                pos = self.currentPosition(gameState)
                if self.getMazeDistance(pos, e1pos) > self.getMazeDistance(pos, e2pos):
                    return e2
                else:
                    return e1

    def successorPos(self, pos):
        """
        next possible legal position
        """
        x, y = pos
        possibleSucc = [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]
        successors = filter(lambda x: x in self.legalPosSet, possibleSucc)
        return successors

    def chooseAction(self, gameState):
        """
        Picks among the actions with the highest Q(s,a).
        """
        newPos = self.currentPosition(gameState)
        actions = gameState.getLegalActions(self.index)
        #return random.choice(actions)
        actions.remove('Stop')
        finalAction = None

        # You can profile your evaluation time by uncommenting these lines
        start = time.time()

        while self.goalFood not in self.foodList(gameState):
            if self.foodBranch.isEmpty():
                mst = self.findFoodMST(gameState)
                self.foodBranch = self.findShortestBranch(mst, newPos)
            self.goalFood = self.foodBranch.pop()

        self.getDefendingFood(gameState)

        self.observeState()

        # display the inference
        distList = self.getBeliefDistribution()
        while False in distList:
            i = distList.index(False)
            distList[i] = util.Counter()
            if i == self.index:
                distList[i][self.currentPosition(gameState)] = 1.0
            else:
                distList[i][self.currentAllyPosition(gameState)] = 1.0
        self.displayDistributionsOverPositions(distList)

        enemy = self.closestPacman(gameState)
        blockage = self.closestGhost(gameState)
        houndDist = 5
        if blockage != -1:
            blockagePos = self.approxEnemyPosition(blockage)
            blockageDist = self.getMazeDistance(newPos, blockagePos)
            if blockageDist <= 4 and\
                    not self.isPacman(gameState, self.index) and \
                    not self.isScared(gameState, self.index):
                houndDist = 5
        if enemy == -1 or self.isScared(gameState, self.index):
            self.hound = False
            self.target = -1
        elif enemy != self.allyAgent.target:
            enemyPos = self.approxEnemyPosition(enemy)
            enemyDist = self.getMazeDistance(newPos, enemyPos)
            #radarPower = 1 - (1.0 * self.getScore(gameState)) / self.numAllFood
            if (self.isPacman(gameState, self.index) and \
                    enemyDist <= 2) or \
               (not self.isPacman(gameState, self.index) and \
                    enemyDist <= houndDist):
                if not self.hound and self.target != enemy:
                    print "Enemy " + str(enemy) + ", I will seek you, I will find you, I will break you."
                    self.hound = True
                    self.target = enemy

        values = [self.evaluate(gameState, a) for a in actions]

        maxValue = max(values)
        bestActions = [a for a, v in zip(actions, values) if v == maxValue]
        
        finalAction = random.choice(bestActions)

        x, y = newPos
        foodList = self.foodList(gameState)
        if len(foodList) <= 3:  # winning combo
            if (x, y + 1) in foodList:
                finalAction = 'North'
            elif (x, y - 1) in foodList:
                finalAction = 'South'
            elif (x + 1, y) in foodList:
                finalAction = 'East'
            elif (x - 1, y) in foodList:
                finalAction = 'West'

        nextPos = None
        if finalAction == 'North':
            nextPos = (x, y + 1)
        elif finalAction == 'South':
            nextPos = (x, y - 1)
        elif finalAction == 'East':
            nextPos = (x + 1, y)
        elif finalAction == 'West':
            nextPos = (x - 1, y)

        allEnemyPos = list(map(self.approxEnemyPosition, self.enemyIndices))
        if allEnemyPos[0] == nextPos:
            i = self.enemyIndices[0]
            self.allParticles[i] = self.sendParticlesHome(i)
            self.allyAgent.allParticles[i] = self.sendParticlesHome(i)
        if allEnemyPos[1] == nextPos:
            i = self.enemyIndices[1]
            self.allParticles[i] = self.sendParticlesHome(i)
            self.allyAgent.allParticles[i] = self.sendParticlesHome(i)

        timeElapse = time.time() - start
        if timeElapse >= 1.0:
            print 'eval time for agent %d: %.4f' % \
                    (self.index, timeElapse)

        return finalAction

    def getSuccessor(self, gameState, action):
        """
        Finds the next successor which is a grid position (location tuple).
        """
        successor = gameState.generateSuccessor(self.index, action)
        pos = successor.getAgentState(self.index).getPosition()
        if pos != nearestPoint(pos):
            # Only half a grid position was covered
            return successor.generateSuccessor(self.index, action)
        else:
            return successor

    def evaluate(self, gameState, action):
        """
        Computes many different things
        """
        features = self.getFeatures(gameState, action)
        succ = self.getSuccessor(gameState, action)
        newPos = self.currentPosition(succ)
        # use current position and food positions to make MST
        # and then find the length of the shortest branch

        enemyPacmanDist = -5
        enemyPacman = self.closestPacman(gameState)
        enemyGhost = self.closestGhost(gameState)
        # if marked down an enemy, pursue it
        if self.hound:
            enemyPacmanPos = self.approxEnemyPosition(self.target)
            enemyPacmanDist = self.getMazeDistance(newPos, enemyPacmanPos)
            if newPos == enemyPacmanPos:
                return 8000
            else:
                return -100 * enemyPacmanDist
        # if unscared ghost is near, do minimax/expectimax
        if enemyGhost != -1:
            ghostPos = self.approxEnemyPosition(enemyGhost)
            ghostDist = self.getMazeDistance(newPos, ghostPos)
            #if ghostDist == 0:
            #    return -10000000
            #elif ghostDist == 1:
            #    return -500000
            if ghostDist < self.minimaxDist:
                return self.minimax(gameState, action)

        # if ate something, PROFIT!!!
        returnVal = 0
        numFood = self.foodSearch(gameState, action)
        if features['ateGhost'] > 0:
            returnVal += 5000
        if features['ateFood'] > 0:
            returnVal += 3000 + self.foodDepth * 100  # actual food is more enticing
        elif not self.isScared(gameState, self.enemyIndices[0]) and \
                not self.isScared(gameState, self.enemyIndices[1]) and \
                features['ateCapsule'] > 0:
            returnVal += 5000

        #if numFood > 0:
        #    returnVal += 100 * numFood
        #else:
        returnVal += -100.0 * self.getMazeDistance(newPos, self.goalFood)
        return returnVal

    def getFeatures(self, gameState, action):
        """
        Returns a counter of features for the state
        """
        features = util.Counter()
        # extract the basic information
        successor = self.getSuccessor(gameState, action)
        newPos = self.currentPosition(successor)

        newFood = self.adjustedFoodList(successor)
        foodDist = \
            list(map(lambda x: self.getMazeDistance(newPos, x), newFood))

        allDistrib = self.getBeliefDistribution()

        allAgentPos = []
        for i in range(self.numAgents):
            if i in self.teamIndices:
                allAgentPos.append((0,0))
            else:
                allAgentPos.append(allDistrib[i].argMax())

        atePacman = False
        ateGhost = False
        wasEaten = False
        if newPos in allAgentPos:
            i = allAgentPos.index(newPos)
            if self.isPacman(successor, i):
                if not self.isScared(successor, self.index):
                    atePacman = True
                else:
                    wasEaten = True
            else:
                if self.isScared(successor, i):
                    ateGhost = True
                else:
                    wasEaten = True

        enemyPacmanPos = []
        enemyGhostPos = []
        for i in range(self.numAgents):
            if i in self.enemyIndices:
                if gameState.getAgentState(i).isPacman:
                    enemyPacmanPos.append(allAgentPos[i])
                elif gameState.getAgentState(i).scaredTimer == 0:
                    enemyGhostPos.append(allAgentPos[i])

        enemyPacmanDist = \
            list(map(lambda x: self.getMazeDistance(newPos, x), enemyPacmanPos))
        enemyGhostDist = \
            list(map(lambda x: self.getMazeDistance(newPos, x), enemyGhostPos))

        enemyPacmanDist.append(0)
        enemyGhostDist.append(10)

        ateCaps = False
        if newPos in self.getCapsules(gameState):
            ateCaps = True

        originPos = self.startPositions[self.index]

        # ...and extract the features
        features['bias'] = 1.0

        if len(self.getFood(gameState).asList(True)) - len(self.getFood(successor).asList(True)):
            features['ateFood'] = 1.0

        if ateCaps:
            features['ateCapsule'] = 1.0

        if atePacman:
            features['atePacman'] = 1.0

        if ateGhost:
            features['ateGhost'] = 1.0

        if wasEaten:
            features['wasEaten'] = 1.0

        if foodDist:
            features['foodDist'] = min(foodDist) * 1.0

        if enemyPacmanDist:
            n = len(enemyPacmanDist)
            features['enemyPacmanDist'] = min(enemyPacmanDist) * n
        else:
            features['enemyPacmanDist'] = 10

        if enemyGhostDist:
            features['enemyGhostDist'] = min(enemyGhostDist) * 1.0
        else:
            features['enemyGhostDist'] = 20

        features['successorScore'] = self.getScore(successor)

        return features

    def minimax(self, gameState, action):
        """
        Simplified case of minimax with a touch of expectimax.
        If enters the area the enemy would arrive in d step,
        mark it minimized for the most of the time.
        Otherwise, maximize the food.
        """
        succ = self.getSuccessor(gameState, action)
        oldPos = self.currentPosition(gameState)
        newPos = self.currentPosition(succ)
        visitedSet = {oldPos}

        enemyIndex1 = self.enemyIndices[0]
        enemyIndex2 = self.enemyIndices[1]
        enemyPos1 = self.approxEnemyPosition(enemyIndex1)
        enemyPos2 = self.approxEnemyPosition(enemyIndex2)
        enemyNextPos1 = set(self.successorPos(enemyPos1))
        enemyNextPos2 = set(self.successorPos(enemyPos2))
        dist1 = self.getMazeDistance(newPos, enemyPos1)
        dist2 = self.getMazeDistance(newPos, enemyPos2)
        if dist1 == 0 or dist2 == 0:
            return -10000000
        if dist1 == 1 or dist2 == 1:
            return -500000

        visitedSet.add(enemyPos1)
        visitedSet.add(enemyPos2)
        visitedSet = visitedSet | enemyNextPos1 | enemyNextPos2

        foodAte = 0
        foodSet = set(self.adjustedFoodList(gameState))
        caps = False
        v, caps= self.maximizeGain(1, newPos, foodAte, foodSet, visitedSet, caps)
        if caps:
            v += 50000
        return v

    def maximizeGain(self, d, newPos, foodAte, foodSet, visitedSet, caps):
        """
        maximize survivability and food intake
        """
        gameState = self.getCurrentObservation()
        visitedSet.add(newPos)
        if newPos in foodSet:
            foodAte += 3000
            foodSet.remove(newPos)
        if len(foodSet) <= 2:
            foodSet = set(self.foodList(gameState)) - visitedSet
            if len(foodSet) <= 2:
                return 10000000, caps
        if newPos in self.getCapsules(gameState):
            foodAte += 1000000
            caps = True
        foodDist = \
            list(map(lambda x: self.getMazeDistance(newPos, x), list(foodSet)))
        if not foodDist:
            foodDist.append(0)

        foodAte += 2.0 / (1 + min(foodDist))

        succ = self.successorPos(newPos)
        succ = list(set(succ) - visitedSet)

        # if the depth was achieved
        if d == self.depth and succ:
            return 50000 + foodAte, caps
        # if it is a dead end
        elif not succ:
            if not caps:
                enemyIndex1 = self.enemyIndices[0]
                enemyIndex2 = self.enemyIndices[1]
                x, y = 0, 0
                pos1 = self.approxEnemyPosition(enemyIndex1)
                dist1 = self.getMazeDistance(newPos, pos1)
                pos2 = self.approxEnemyPosition(enemyIndex2)
                dist2 = self.getMazeDistance(newPos, pos2)
                # if ghost will surely follow you, don't go.
                if (dist1 <= d + 1 and \
                        not self.isScared(gameState, enemyIndex1)) or \
                   (dist2 <= d + 1 and \
                        not self.isScared(gameState, enemyIndex2)):
                    return foodAte - 500000, caps
                # if there's a chance you can escape, take that chance
                if dist1 <= self.depth - d:
                    if not self.isScared(gameState, enemyIndex1) and \
                            random.random() < self.probLogicalEnemy:
                        #foodAte = 0
                        x = -30000 # * math.pow(self.discount, d)
                if dist2 <= self.depth - d:
                    if not self.isScared(gameState, enemyIndex2) and \
                            random.random() < self.probLogicalEnemy:
                        #foodAte = 0
                        y = -30000 # * math.pow(self.discount, d)
                return foodAte + x + y, caps
            else:
                return foodAte, caps

        return max([self.minimizeGain(d, p, foodAte, foodSet,
                                      visitedSet, caps)[0] for p in succ]), caps

    def minimizeGain(self, d, newPos, foodAte, foodSet, visitedSet, caps):
        """
        imitate enemy trying to step on our way
        """
        gameState = self.getCurrentObservation()
        foodAte, caps = self.maximizeGain(d + 1, newPos, foodAte,
                                          foodSet, visitedSet, caps)
        enemyIndex1 = self.enemyIndices[0]
        enemyIndex2 = self.enemyIndices[1]
        x, y = 0, 0
        if not caps:
            dist1 = self.getMazeDistance(newPos, self.approxEnemyPosition(enemyIndex1))
            dist2 = self.getMazeDistance(newPos, self.approxEnemyPosition(enemyIndex2))
            if dist1 == 0 or dist2 == 0:
                return -10000000, caps
            if dist1 == 1 or dist2 == 1:
                return -500000, caps
            if dist1 <= self.depth - d:
                if not self.isScared(gameState, enemyIndex1) and \
                        random.random() < self.probLogicalEnemy:
                    #foodAte = 0
                    x = -30000 # * math.pow(self.discount, d)
            if dist2 <= self.depth - d:
                if not self.isScared(gameState, enemyIndex2) and \
                        random.random() < self.probLogicalEnemy:
                    #foodAte = 0
                    y = -30000 # * math.pow(self.discount, d)
        return foodAte + x + y, caps

    def getWeights(self, gameState, action):
        """
        Normally, weights do not depend on the gamestate.  They can be either
        a counter or a dictionary.
        """
        return self.weight

    def initializeAllParticles(self):
        """
        Initialize all particle filters
        """
        self.allParticles = []
        for eachAgent in range(self.numAgents):
            particles = []
            if eachAgent in self.enemyIndices:
                # To initialize uniformly, uncomment
                particles = self.repopulateParticlesUniformly()
                # To initialize with start position knowledge, uncomment
                # particles = self.sendParticlesHome(eachAgent)
            self.allParticles.append(particles)

    def repopulateParticlesUniformly(self):
        """
        Repopulate particles if something goes wrong
        """
        print "A glass of well-mixed particles. Shaken, not stirred."
        particles = []
        positions = self.legalPositions[:]
        while len(particles) < self.numParticles:
            random.shuffle(positions)
            particles += positions
        return particles[:self.numParticles]

    def sendParticlesHome(self, enemyIndex):
        """
        Update the particles to reflect eaten enemy
        """
        part = self.startPositions[enemyIndex]
        return [part for num in range(self.numParticles)]

    def updateParticleVisible(self):
        """
        Update the particles to reflect visible enemy
        """
        gameState = self.getCurrentObservation()
        for i in self.enemyIndices:
            part = gameState.getAgentPosition(i)
            if part:
                self.allParticles[i] = \
                    [part for j in range(self.numParticles)]
                self.allyAgent.allParticles[i] = \
                    [part for j in range(self.numParticles)]

    def moveParticle(self, part):
        """
        Move a particle to a reasonable random position
        """
        x, y = part
        moveList = ['North', 'South', 'East', 'West', 'Stop']
        if (x + 1, y) not in self.legalPositions:
            moveList.remove('East')
        if (x - 1, y) not in self.legalPositions:
            moveList.remove('West')
        if (x, y + 1) not in self.legalPositions:
            moveList.remove('North')
        if (x, y - 1) not in self.legalPositions:
            moveList.remove('South')

        # three times as likely to go to food
        if (x + 1, y) in self.defFood:
            moveList.append('East')
            moveList.append('East')
        if (x - 1, y) in self.defFood:
            moveList.append('West')
            moveList.append('West')
        if (x, y + 1) in self.defFood:
            moveList.append('North')
            moveList.append('North')
        if (x, y - 1) in self.defFood:
            moveList.append('South')
            moveList.append('South')

        nextMove = random.choice(moveList)
        if nextMove == 'North':
            return (x, y + 1)
        if nextMove == 'South':
            return (x, y - 1)
        if nextMove == 'East':
            return (x + 1, y)
        if nextMove == 'West':
            return (x - 1, y)
        return (x, y)

    def observeState(self):
        """
        Observe over time and resample
        """
        gameState = self.getCurrentObservation()


        # code below for reinitalizing for only one enemy
        #enemyIndex = (self.index - 1) % 4
        # move particle randomly over time elapse
        #particles = self.allParticles[enemyIndex]
        #updatedParticles = []
        #for part in particles:
        #    updatedParticles.append(self.moveParticle(part))
        #if not self.isPacman(gameState, enemyIndex):
        #particles = updatedParticles
        #updatedParticles = []
        #for part in particles:
        #    updatedParticles.append(self.moveParticle(part))
        #self.allParticles[enemyIndex] = updatedParticles


        # code below for reinitializing for both enemies
        # move particle randomly over time elapse
        particles = self.allParticles[self.enemyIndices[0]]
        updatedParticles = []
        for part in particles:
            updatedParticles.append(self.moveParticle(part))
        self.allParticles[self.enemyIndices[0]] = updatedParticles

        particles = self.allParticles[self.enemyIndices[1]]
        updatedParticles = []
        for part in particles:
            updatedParticles.append(self.moveParticle(part))
        self.allParticles[self.enemyIndices[1]] = updatedParticles


        # ...and do it for the friend too
        #particles = self.allyAgent.allParticles[enemyIndex]
        #updatedParticles = []
        #for part in particles:
        #    updatedParticles.append(self.moveParticle(part))
        #if not self.isPacman(gameState, enemyIndex):
        #    particles = updatedParticles
        #    updatedParticles = []
        #    for part in particles:
        #        updatedParticles.append(self.moveParticle(part))
        #self.allyAgent.allParticles[enemyIndex] = updatedParticles

        particles = self.allyAgent.allParticles[self.enemyIndices[0]]
        updatedParticles = []
        for part in particles:
            updatedParticles.append(self.moveParticle(part))
        self.allyAgent.allParticles[self.enemyIndices[0]] = updatedParticles

        particles = self.allyAgent.allParticles[self.enemyIndices[1]]
        updatedParticles = []
        for part in particles:
            updatedParticles.append(self.moveParticle(part))
        self.allyAgent.allParticles[self.enemyIndices[1]] = updatedParticles

        pos = self.currentPosition(gameState)

        # convert to distribution, apply probability, resample
        allDistance = gameState.getAgentDistances()
        allDistrib = []
        allAllyDistrib = []

        # redo it if something f*cks up
        recreate = True
        while recreate:
            recreate = False
            # get distributions for all (enemy) agents
            allDistrib = self.getBeliefDistribution()
            allAllyDistrib = self.allyAgent.getBeliefDistribution()

            for i in self.enemyIndices:
                noisyDist = allDistance[i]
                for p in self.legalPositions:
                    # adjust distribution by likelihood
                    trueDist = util.manhattanDistance(p, pos)
                    prob = allDistrib[i][p] * \
                        gameState.getDistanceProb(trueDist, noisyDist)
                    probAlly = allAllyDistrib[i][p] * \
                        gameState.getDistanceProb(trueDist, noisyDist)
                    allDistrib[i][p] = prob
                    allDistrib[i][p] = probAlly
                # if something really got f*cked up
                # regenerate the particle for the agent
                if allDistrib[i].totalCount() == 0:
                    self.allParticles[i] = \
                        self.repopulateParticlesUniformly()
                    self.allyAgent.allParticles[i] = \
                        self.repopulateParticlesUniformly()
                    recreate = True
                else:
                    allDistrib[i].normalize()
                    allAllyDistrib[i].normalize()

        # then use the all distribution to recreate particles
        self.allParticles = []
        self.allyAgent.allParticles = []
        for i in range(self.numAgents):
            particles = []  # if it is ours, append dummy data
            if i in self.enemyIndices:
                particles = [util.sample(allDistrib[i])
                             for n in range(self.numParticles)]
            self.allParticles.append(particles)
            if i in self.enemyIndices:
                particles = [util.sample(allAllyDistrib[i])
                             for n in range(self.numParticles)]
            self.allyAgent.allParticles.append(particles)

        # finally, update particles for the enemys that are visible
        self.updateParticleVisible()

    def getBeliefDistribution(self):
        """
        Belief state based on particles
        """
        allPossibleDist = []
        redo = True
        while redo:
            redo = False
            for i in range(self.numAgents):
                possibleDistA = util.Counter()
                particlesA = self.allParticles[i]
                if particlesA:  # not our agent
                    for part in particlesA:
                        possibleDistA[part] += 1.0
                    possibleDistA.normalize()
                    if possibleDistA.argMax == 0:
                        redo = True
                        self.allParticles[i] = \
                            self.repopulateParticlesUniformly()
                else:
                    possibleDistA = False
                allPossibleDist.append(possibleDistA)
        return allPossibleDist

    def getAgentPositions(self):
        """
        List of agent positions (self & ally = (0, 0))
        """
        allDistrib = self.getBeliefDistribution()
        allAgentPos = []
        for i in range(self.numAgents):
            if i in self.teamIndices:
                allAgentPos.append((0,0))
            else:
                allAgentPos.append(allDistrib[i].argMax())
        return allAgentPos

    def getAllyPosition(self):
        gameState = self.getCurrentObservation()
        allyIndex = -1
        if self.teamIndices[0] == self.index:
            allyIndex = self.teamIndices[1]
        else:
            allyIndex = self.teamIndices[0]
        return gameState.getAgentState(allyIndex).getPosition()
